{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules and read in data\n",
    "\n",
    "First, we will import all the modules needed for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mixed_sigmoid_normalisation import MixedSigmoidScaler,mixed_sigmoid_func\n",
    "\n",
    "# Set seed to 127\n",
    "random.seed(127)\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "    library(broom)\n",
    "    library(circlize)\n",
    "    library(ComplexHeatmap)\n",
    "    library(cowplot)\n",
    "    library(dendextend)\n",
    "    library(FactoMineR)\n",
    "    library(GGally)\n",
    "    library(ggseg)\n",
    "    library(glue)\n",
    "    library(grid)\n",
    "    library(patchwork)\n",
    "    library(see)\n",
    "    library(tidyverse)\n",
    "})\n",
    "\n",
    "# Set cowplot theme\n",
    "theme_set(theme_cowplot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory\n",
    "infotheory_measure_dir = \"infotheory_measures/\"\n",
    "\n",
    "# Load SPI groupings\n",
    "infotheory_measure_info = pd.read_csv(\"infotheory_measure_info.csv\")\n",
    "\n",
    "# Find .csv files in the data directory\n",
    "all_subjects_info_theory_res = pd.concat([pd.read_csv(f) for f in glob(infotheory_measure_dir + \"*.csv\")]).merge(infotheory_measure_info, on=\"Measure\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure</th>\n",
       "      <th>region_from</th>\n",
       "      <th>region_to</th>\n",
       "      <th>Measure_Type</th>\n",
       "      <th>value</th>\n",
       "      <th>Base_Region</th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Measure_name</th>\n",
       "      <th>Group</th>\n",
       "      <th>Group_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entropy_kozachenko</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>1.420351</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td>176542</td>\n",
       "      <td>Entropy</td>\n",
       "      <td>Univariate order-independent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIS_kraskov</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>0.554316</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td>176542</td>\n",
       "      <td>Active information storage</td>\n",
       "      <td>Univariate order-dependent</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entropy_kozachenko</td>\n",
       "      <td>parsopercularis</td>\n",
       "      <td>parsopercularis</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>1.385257</td>\n",
       "      <td>parsopercularis</td>\n",
       "      <td>176542</td>\n",
       "      <td>Entropy</td>\n",
       "      <td>Univariate order-independent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIS_kraskov</td>\n",
       "      <td>parsopercularis</td>\n",
       "      <td>parsopercularis</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>parsopercularis</td>\n",
       "      <td>176542</td>\n",
       "      <td>Active information storage</td>\n",
       "      <td>Univariate order-dependent</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>je_kozachenko</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td>parsopercularis</td>\n",
       "      <td>Bivariate</td>\n",
       "      <td>2.833943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176542</td>\n",
       "      <td>Joint entropy</td>\n",
       "      <td>Bivariate order-independent, undirected</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Measure       region_from         region_to Measure_Type  \\\n",
       "0  entropy_kozachenko  lateraloccipital  lateraloccipital   Univariate   \n",
       "1         AIS_kraskov  lateraloccipital  lateraloccipital   Univariate   \n",
       "2  entropy_kozachenko   parsopercularis   parsopercularis   Univariate   \n",
       "3         AIS_kraskov   parsopercularis   parsopercularis   Univariate   \n",
       "4       je_kozachenko  lateraloccipital   parsopercularis    Bivariate   \n",
       "\n",
       "      value       Base_Region  Sample_ID                Measure_name  \\\n",
       "0  1.420351  lateraloccipital     176542                     Entropy   \n",
       "1  0.554316  lateraloccipital     176542  Active information storage   \n",
       "2  1.385257   parsopercularis     176542                     Entropy   \n",
       "3  0.240965   parsopercularis     176542  Active information storage   \n",
       "4  2.833943               NaN     176542               Joint entropy   \n",
       "\n",
       "                                     Group  Group_number  \n",
       "0             Univariate order-independent             1  \n",
       "1               Univariate order-dependent             4  \n",
       "2             Univariate order-independent             1  \n",
       "3               Univariate order-dependent             4  \n",
       "4  Bivariate order-independent, undirected             2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_info_theory_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`summarise()` has grouped output by 'region_to', 'Measure_name'. You can\n",
      "override using the `.groups` argument.\n",
      "Joining with `by = join_by(label)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "merging atlas and data by 'label', 'atlas', 'type', 'hemi', 'side', 'region', 'roi'\n",
       "In addition: Warning message:\n",
       "In left_join(., as_tibble(dk)) :\n",
       "  Detected an unexpected many-to-many relationship between `x` and `y`.\n",
       "ℹ Row 67 of `x` matches multiple rows in `y`.\n",
       "ℹ Row 2 of `y` matches multiple rows in `x`.\n",
       "ℹ If a many-to-many relationship is expected, set `relationship =\n",
       "  \"many-to-many\"` to silence this warning.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i all_subjects_info_theory_res -o mean_measure_value_by_region\n",
    "\n",
    "# Generate default color palette\n",
    "gg_color_hue <- function(n) {\n",
    "      hues = seq(15, 375, length = n + 1)\n",
    "      hcl(h = hues, l = 65, c = 100)[1:n]\n",
    "      }\n",
    "group_colors <- gg_color_hue(6)\n",
    "\n",
    "# Let's plot this in the brain\n",
    "mean_measure_value_by_region <- all_subjects_info_theory_res %>%\n",
    "  group_by(region_to, Measure_name, Group_number) %>%\n",
    "  summarise(mean_value = mean(value, na.rm=T)) %>%\n",
    "  ungroup() %>%\n",
    "  mutate(label = glue(\"lh_{region_to}\"),\n",
    "         mean_value = ifelse(mean_value<0, NA_real_, mean_value))\n",
    "  \n",
    "mean_measure_value_by_region_dk <- mean_measure_value_by_region %>%\n",
    "  left_join(., as_tibble(dk))\n",
    "\n",
    "plot_list <- list()\n",
    "for (measure in unique(mean_measure_value_by_region_dk$Measure_name)) {\n",
    "      this_measure_data <- subset(mean_measure_value_by_region_dk, Measure_name==measure)\n",
    "      measure_group_color <- group_colors[this_measure_data$Group_number][1]\n",
    "      p <- mean_measure_value_by_region_dk %>%\n",
    "            filter(Measure_name==measure) %>%\n",
    "            ggseg(atlas = dk, \n",
    "                  # mapping = aes(fill = mean_value_norm),\n",
    "                  mapping=aes(fill=mean_value),\n",
    "                  position = \"stacked\", colour = \"gray40\", hemisphere=\"left\") +\n",
    "            theme_void() +\n",
    "            labs(fill = measure) +\n",
    "            theme(plot.title = element_blank(),\n",
    "                  legend.key.width = unit(0.45, \"cm\"),\n",
    "                  legend.key.height = unit(0.35, \"cm\"),\n",
    "                  legend.position = \"bottom\") +\n",
    "            scale_fill_gradient(low=\"white\", high=measure_group_color, na.value=\"white\")\n",
    "      plot_list[[measure]] <- p\n",
    "}\n",
    "\n",
    "wrap_plots(plot_list)\n",
    "ggsave(\"../SPIs/figure_drafting/info_theory_measures_in_brain_100_subjects.svg\", width=10, height=5, units=\"in\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this subject's time series\n",
    "# z-score each column\n",
    "subject_TS_data = pd.DataFrame(StandardScaler().fit_transform(np.load(f\"{data_dir}/{subject_ID}.npy\").T))\n",
    "subject_TS_data.columns = brain_region_lookup.Brain_Region.values\n",
    "\n",
    "subject_TS_data['Timepoint'] = subject_TS_data.index + 1\n",
    "\n",
    "# Extract the source region time series\n",
    "source_region_TS = subject_TS_data[[f\"ctx-lh-{source_base_region}\", \"Timepoint\"]].rename(columns={f\"ctx-lh-{source_base_region}\": \"BOLD_Signal\"})\n",
    "\n",
    "# Melt the data\n",
    "subject_TS_data_melted = subject_TS_data.melt(id_vars=\"Timepoint\", var_name=\"Brain_Region\", value_name=\"BOLD_Signal\")\n",
    "\n",
    "# Find the min and max value per measure, keeping the brain region\n",
    "min_max_region_agg = (this_subject_infotheory_results\n",
    "                      .groupby(\"Measure_name\")['value_norm']\n",
    "                      .agg(['min', 'max'])\n",
    "                      .reset_index()\n",
    "                      .melt(id_vars=\"Measure_name\", var_name=\"variable\", value_name=\"value_norm\")\n",
    "                      .merge(this_subject_infotheory_results, on=[\"Measure_name\", \"value_norm\"], how=\"left\")\n",
    "                      .drop(columns=[\"Base_Region\"])\n",
    "                      .rename(columns={\"region_to\": \"Base_Region\"})\n",
    "                    )\n",
    "\n",
    "min_max_TS_data = subject_TS_data_melted.merge(brain_region_lookup, on=\"Brain_Region\").merge(min_max_region_agg, on=\"Base_Region\").query(\"Hemisphere=='Left'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i source_region_TS\n",
    "\n",
    "source_region_TS %>% \n",
    "    ggplot(data=., mapping=aes(x=Timepoint, y=BOLD_Signal)) +\n",
    "    geom_line(linewidth=0.4, color=\"#be7edf\") +\n",
    "    theme_void() +\n",
    "    theme(legend.position=\"none\") \n",
    "\n",
    "# ggsave(\"../SPIs/figure_drafting/left_lateral_occipital_TS.svg\", width=4, height=1, units=\"in\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i min_max_TS_data \n",
    "\n",
    "min_max_TS_data %>% \n",
    "    ggplot(data=., mapping=aes(x=Timepoint, y=BOLD_Signal, color=as.factor(Group_number))) +\n",
    "    geom_line(linewidth=0.4) +\n",
    "    facet_grid(Measure_name~variable) +\n",
    "    theme_void() +\n",
    "    theme(legend.position=\"none\") \n",
    "# ggsave(\"../SPIs/figure_drafting/info_theory_measures_min_max_TS.svg\", width=6, height=12, units=\"in\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down the JVM at the end of session\n",
    "jpype.shutdownJVM() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are the measures correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_wise_corrs = mean_measure_value_by_region.pivot(index=\"region_to\", columns=\"Measure_name\", values=\"mean_value_norm\").corr(method=\"spearman\")\n",
    "\n",
    "measure_wise_corrs_bivar =  mean_measure_value_by_region.query(\"Measure_name not in ['Active information storage', 'Entropy']\").pivot(index=\"region_to\", columns=\"Measure_name\", values=\"mean_value_norm\").corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i measure_wise_corrs,measure_wise_corrs_bivar\n",
    "\n",
    "# svg(\"../SPIs/figure_drafting/infotheory_measure_corrs_across_brain_bivar.svg\", width=7, height=5, bg=NA)\n",
    "ht1 <- ComplexHeatmap::Heatmap(measure_wise_corrs_bivar,\n",
    "                                clustering_method_rows = \"ward.D2\",\n",
    "                                clustering_method_columns = \"ward.D2\",\n",
    "                                row_names_side = \"right\",\n",
    "                                row_dend_side = \"left\", \n",
    "                                row_dend_width = unit(1, \"cm\"),\n",
    "                                row_dend_gp = gpar(lwd=unit(0.5, \"cm\")),\n",
    "                                row_split = 4,\n",
    "                                column_split = 3,\n",
    "                                row_title = NULL,\n",
    "                                column_title = NULL,\n",
    "                                show_row_names = TRUE,\n",
    "                                show_column_names = FALSE,\n",
    "                                name = \"Spearman corr\",\n",
    "                                show_column_dend = FALSE,\n",
    "                                heatmap_legend_param = list(legend_direction = \"horizontal\",\n",
    "                                                            legend_width = unit(5, \"cm\"))) \n",
    "\n",
    "draw(ht1, heatmap_legend_side = \"bottom\",\n",
    "    padding = unit(c(2, 2, 2, 2), \"mm\"),\n",
    "    background = \"transparent\")\n",
    "# dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot entropy histogram in the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_subject_infotheory_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max value_norm per Measure_name, keeping the region_from and region_to columns\n",
    "\n",
    "entropy_min_max = (this_subject_infotheory_results\n",
    "                      .query(\"Measure_name == 'Entropy'\")\n",
    "                      .groupby(\"Measure_name\")['value_norm']\n",
    "                      .agg(['min', 'max'])\n",
    "                      .reset_index()\n",
    "                      .melt(id_vars=\"Measure_name\", var_name=\"variable\", value_name=\"value_norm\")\n",
    "                      .merge(this_subject_infotheory_results, on=[\"Measure_name\", \"value_norm\"], how=\"left\")\n",
    "                      .sort_values(['Measure_name', 'variable'])\n",
    ")\n",
    "entropy_min_region = entropy_min_max.query(\"variable == 'min'\").region_from.values[0]\n",
    "entropy_max_region = entropy_min_max.query(\"variable == 'max'\").region_from.values[0]\n",
    "entropy_min_TS = subject_TS_data_melted.query(f\"Brain_Region == 'ctx-lh-{entropy_min_region}'\").assign(Entropy = \"min\")\n",
    "entropy_max_TS = subject_TS_data_melted.query(f\"Brain_Region == 'ctx-lh-{entropy_max_region}'\").assign(Entropy = \"max\")\n",
    "\n",
    "entropy_min_max_df = pd.concat([entropy_min_TS, entropy_max_TS])\n",
    "\n",
    "entropy_min_max_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i entropy_min_max_df\n",
    "\n",
    "entropy_min_max_df %>%\n",
    "    group_by(Entropy) %>%\n",
    "    mutate(mean_x = mean(BOLD_Signal)) %>% \n",
    "    ggplot(data=., mapping=aes(x=BOLD_Signal, fill=Entropy)) +\n",
    "    # geom_histogram(position='identity', alpha=0.7, bins=50) +\n",
    "    geom_density(position='identity', alpha=0.7) +\n",
    "    scale_y_continuous(expand=c(0,0)) +\n",
    "    facet_wrap(Entropy ~ ., nrow=1, scales='fixed') +\n",
    "    scale_fill_manual(values=c(\"min\"=\"#FFEFED\", \"max\" = \"#F9766D\")) +\n",
    "    xlab(\"BOLD signal\") +\n",
    "    geom_vline(aes(xintercept=mean_x), linetype=\"dashed\", size=0.5) +\n",
    "    theme(legend.position='none',\n",
    "          strip.text = element_blank(),\n",
    "          strip.background = element_blank())\n",
    "ggsave('../SPIs/figure_drafting/entropy_min_max_TS_density.svg', width=6, height=2, units=\"in\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy_min_TS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
